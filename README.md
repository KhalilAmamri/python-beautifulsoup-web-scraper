# ğŸ† YallaKora Match Scraper

[![CI/CD Pipeline](https://github.com/KhalilAmamri/python-beautifulsoup-web-scraper/actions/workflows/ci.yml/badge.svg)](https://github.com/KhalilAmamri/python-beautifulsoup-web-scraper/actions/workflows/ci.yml)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A professional Python web scraper that extracts football match data from [YallaKora](https://www.yallakora.com/) for any specified date and saves it to structured CSV files.

---

## âœ¨ Features

- ğŸ¯ **Smart Date Validation**: Robust date format validation with proper error handling
- ğŸŒ **Reliable Web Scraping**: Handles dynamic website structure changes
- ğŸ† **Multi-Championship Support**: Extracts matches from all available championships
- ğŸ“Š **Structured Data Export**: Clean CSV output with proper encoding
- ğŸ”§ **Professional Code Structure**: Object-oriented design with proper error handling
- ğŸ“ **Comprehensive Logging**: Detailed logs for debugging and monitoring
- ğŸ§ª **Unit Tested**: Comprehensive test suite for reliability
- ğŸš€ **CI/CD Ready**: GitHub Actions integration for automated testing
- ğŸ’» **Command Line Interface**: Easy-to-use CLI with multiple options

---

## ğŸ“‹ Project Structure

```
python-beautifulsoup-web-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ yallakora_scraper.py    # Main scraper class
â”‚   â””â”€â”€ config.py               # Configuration settings
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_scraper.py         # Unit tests
â”œâ”€â”€ data/                       # Output CSV files (auto-created)
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml              # GitHub Actions CI/CD
â”œâ”€â”€ cli.py                      # Command line interface
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # Project documentation
```

---

## ğŸ–¥ï¸ Preview

ğŸ“ Example CSV output:

```csv
championship;first_team;second_team;score;time
ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù… Ù„Ù„Ø£Ù†Ø¯ÙŠØ©;Ø§Ù„ØªØ±Ø¬Ù‰ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ;ØªØ´ÙŠÙ„Ø³ÙŠ;0 - 3;04:00
ÙƒØ£Ø³ Ø§Ù„Ø¹Ø§Ù„Ù… Ù„Ù„Ø£Ù†Ø¯ÙŠØ©;Ù„ÙˆØ³ Ø£Ù†Ø¬Ù„ÙˆØ³;ÙÙ„Ø§Ù…Ù†Ø¬Ùˆ;1 - 1;04:00
Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø§Ù„Ù…ØµØ±ÙŠ;Ø§Ù„Ø£Ù‡Ù„ÙŠ;Ø§Ù„Ø²Ù…Ø§Ù„Ùƒ;2 - 1;21:00
```

---

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/KhalilAmamri/python-beautifulsoup-web-scraper.git
cd python-beautifulsoup-web-scraper
```

### 2. Install Dependencies

```bash
# Using pip
pip install -r requirements.txt

# Or using the setup script
pip install -e .
```

### 3. Run the Scraper

#### Interactive Mode

```bash
python src/yallakora_scraper.py
```

#### Command Line Interface

```bash
# Scrape specific date
python cli.py --date 29-09-2025

# Scrape today's matches
python cli.py --today

# Scrape yesterday's matches
python cli.py --yesterday

# Custom output directory
python cli.py --date 29-09-2025 --output my_data

# Verbose logging
python cli.py --date 29-09-2025 --verbose
```

---

## ğŸ§ª Testing

Run the test suite:

```bash
# Install test dependencies
pip install pytest pytest-cov

# Run tests
pytest tests/ -v

# Run tests with coverage
pytest tests/ -v --cov=src --cov-report=html
```

---

## ğŸ“Š Code Quality

This project maintains high code quality standards:

```bash
# Install development tools
pip install black isort flake8 mypy

# Format code
black src/
isort src/

# Lint code
flake8 src/

# Type checking
mypy src/ --ignore-missing-imports
```

---

## ğŸ”§ Configuration

Copy `.env.example` to `.env` and customize:

```bash
cp .env.example .env
```

Available configuration options:

- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR)
- `OUTPUT_DIR`: Directory for CSV files
- `REQUEST_TIMEOUT`: HTTP request timeout in seconds

---

## ğŸ“¦ Requirements

- **Python**: 3.8+ (tested on 3.8, 3.9, 3.10, 3.11, 3.12, 3.13)
- **Dependencies**:
  - `requests` >= 2.31.0
  - `beautifulsoup4` >= 4.12.0
  - `lxml` >= 4.9.0
- **Internet Connection**: Required for web scraping

---

## ğŸ› ï¸ Technologies Used

- **Python 3.8+** ğŸ
- **Web Scraping**: `requests` + `BeautifulSoup4`
- **Data Processing**: `csv`, `pandas-compatible`
- **Testing**: `pytest`, `unittest`
- **CI/CD**: GitHub Actions
- **Code Quality**: `black`, `isort`, `flake8`, `mypy`

---

## ğŸ“ˆ Recent Improvements

- âœ… **Fixed Dynamic Class Names**: Now handles changing CSS class names
- âœ… **Enhanced Error Handling**: Comprehensive exception handling
- âœ… **Professional Structure**: Object-oriented design
- âœ… **Comprehensive Testing**: Unit tests with good coverage
- âœ… **CI/CD Integration**: Automated testing and quality checks
- âœ… **Command Line Interface**: Multiple usage options
- âœ… **Logging System**: Detailed logging for debugging

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/your-username/python-beautifulsoup-web-scraper.git
cd python-beautifulsoup-web-scraper

# Install in development mode
pip install -e .
pip install -r requirements.txt

# Install development tools
pip install pytest black isort flake8 mypy

# Run tests
pytest tests/
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## âš ï¸ Important Notes

- **Website Dependency**: This scraper depends on YallaKora's website structure
- **Rate Limiting**: Be respectful with requests to avoid being blocked
- **Legal Compliance**: Ensure you comply with the website's terms of service
- **Data Usage**: Use scraped data responsibly and ethically

---

## ğŸ†˜ Support

If you encounter any issues:

1. **Check the logs**: Look at `scraper.log` for detailed error information
2. **Review Issues**: Check [GitHub Issues](https://github.com/KhalilAmamri/python-beautifulsoup-web-scraper/issues)
3. **Create an Issue**: Provide detailed information about the problem
4. **Community**: Join discussions and help others

---

## ğŸŒŸ Show Your Support

If this project helped you, please â­ **star** the repository and consider:

- ğŸ´ **Forking** the project
- ğŸ“ **Contributing** improvements
- ğŸ› **Reporting** bugs
- ğŸ’¡ **Suggesting** new features

---

**Made with â¤ï¸ by [Khalil Amemri](https://github.com/KhalilAmamri)**
